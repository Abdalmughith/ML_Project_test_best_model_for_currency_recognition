{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STARGARDT.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdalmughith/machine-learning-projects/blob/master/STARGARDT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kALGDYWn9Bdl",
        "colab_type": "text"
      },
      "source": [
        "**USING ARTIFICIAL INTELLIGENCE FOR DETECTION OF STARGARDT’S DISEASE FUNDUS PHOTOS**\n",
        "\n",
        "***Purpose.*** Formulating an artificial intelligence model to differentiate fundus photos with Stargardt’s disease from normal fundus photos.\n",
        " \n",
        "***Methods***. Fundus photos of eyes with established diagnosis of Stargardt’s disease (n=25) and normal fundi (n=25) were used to train a TenserFlow Google Cloud based Convolutional Neural Network (CNN) containing three convolutional layers followed by two fully connected layer ending with sigmoid activation function. The numeric values of the sigmoid were converted to a percentage value with the smallest corresponding to 0% and the highest to 100%. Values >50% were considered diagnostic for Stargardt’s disease. \n",
        ".\n",
        " \n",
        "***Results.*** The model was tested with fundus photos that were not used for the training of the model. The model was able to diagnose correctly fundus photos with Stargardt’s disease (n=5), (values ranging 60.5-93.9%) vs normal fundi (n=10), (values ranging 15.7-35.3%), (100% specificity and 100% sensitivity).\n",
        " \n",
        "***Conclusions***:The deep learning artificial intelligence model was able to diagnose Stargardt’s disease depending on fundus images with 100% specificity and 100% sensitivity.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlbRMdK59eeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "from numba import jit\n",
        "import os\n",
        "\n",
        "import math\n",
        "import csv\n",
        "from sklearn import preprocessing\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "img_width, img_height = 615, 800\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('image', '', 'Path to image')\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN3xV_-a9nZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def standard_deviation_image(image):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    clahe_output = clahe.apply(image)\n",
        "    result = clahe_output.copy()\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while i < image.shape[0]:\n",
        "        j = 0\n",
        "        while j < image.shape[1]:\n",
        "            sub_image = clahe_output[i:i + 20, j:j + 25]\n",
        "            var = np.var(sub_image)\n",
        "            result[i:i + 20, j:j + 25] = var\n",
        "            j = j + 25\n",
        "        i = i + 20\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_average_intensity(green_channel):\n",
        "    average_intensity = green_channel.copy()\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while i < green_channel.shape[0]:\n",
        "        j = 0\n",
        "        while j < green_channel.shape[1]:\n",
        "            sub_image = green_channel[i:i + 20, j:j + 25]\n",
        "            mean = np.mean(sub_image)\n",
        "            average_intensity[i:i + 20, j:j + 25] = mean\n",
        "            j = j + 25\n",
        "        i = i + 20\n",
        "    result = np.reshape(average_intensity, (average_intensity.size, 1))\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_average_hue(hue_image):\n",
        "    average_hue = hue_image.copy()\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while i < hue_image.shape[0]:\n",
        "        j = 0\n",
        "        while j < hue_image.shape[1]:\n",
        "            sub_image = hue_image[i:i + 20, j:j + 25]\n",
        "            mean = np.mean(sub_image)\n",
        "            average_hue[i:i + 20, j:j + 25] = mean\n",
        "            j = j + 25\n",
        "        i = i + 20\n",
        "    result = np.reshape(average_hue, (average_hue.size, 1))\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_average_saturation(hue_image):\n",
        "    average_hue = hue_image.copy()\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while i < hue_image.shape[0]:\n",
        "        j = 0\n",
        "        while j < hue_image.shape[1]:\n",
        "            sub_image = hue_image[i:i + 20, j:j + 25]\n",
        "            mean = np.mean(sub_image)\n",
        "            average_hue[i:i + 20, j:j + 25] = mean\n",
        "            j = j + 25\n",
        "        i = i + 20\n",
        "    result = np.reshape(average_hue, (average_hue.size, 1))\n",
        "    return result\n",
        "\n",
        "\n",
        "def edge_pixel_image(image, bv_image):\n",
        "    edge_result = image.copy()\n",
        "    edge_result = cv2.Canny(edge_result, 30, 100)\n",
        "    cv2.imwrite('Canny-over-original.jpg', edge_result)\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while i < image.shape[0]:\n",
        "        j = 0\n",
        "        while j < image.shape[1]:\n",
        "            if edge_result[i, j] == 255 and bv_image[i, j] == 255:\n",
        "                edge_result[i, j] = 0\n",
        "            j = j + 1\n",
        "        i = i + 1\n",
        "\n",
        "    newfin = cv2.dilate(edge_result, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)), iterations=1)\n",
        "    return newfin\n",
        "\n",
        "\n",
        "def extract_bv(image):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    contrast_enhanced_green_fundus = clahe.apply(image)\n",
        "    # applying alternate sequential filtering (3 times closing opening)\n",
        "    r1 = cv2.morphologyEx(contrast_enhanced_green_fundus, cv2.MORPH_OPEN,\n",
        "                          cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)), iterations=1)\n",
        "    cv2.imwrite('extract_bv-r1-morphology-opening.jpg', r1)\n",
        "    R1 = cv2.morphologyEx(r1, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)), iterations=1)\n",
        "    cv2.imwrite('extract_bv-R1-morphology-opening.jpg', R1)\n",
        "    r2 = cv2.morphologyEx(R1, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11)), iterations=1)\n",
        "    cv2.imwrite('extract_bv-r2-morphology-opening.jpg', r2)\n",
        "    R2 = cv2.morphologyEx(r2, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11)), iterations=1)\n",
        "    cv2.imwrite('extract_bv-R2-morphology-opening.jpg', R2)\n",
        "    r3 = cv2.morphologyEx(R2, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (23, 23)), iterations=1)\n",
        "    cv2.imwrite('extract_bv-r3-morphology-opening.jpg', r3)\n",
        "    R3 = cv2.morphologyEx(r3, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (23, 23)), iterations=1)\n",
        "    cv2.imwrite('extract_bv-R3-morphology-opening.jpg', R3)\n",
        "    f4 = cv2.subtract(R3, contrast_enhanced_green_fundus)\n",
        "    cv2.imwrite('extract_bv_subtractfrom_ogienal.jpg', f4)\n",
        "    f5 = clahe.apply(f4)\n",
        "    cv2.imwrite('extract_bv_subtractfrom_ogienal-histogram.jpg', f5)\n",
        "    # removing very small contours through area parameter noise removal\n",
        "    ret, f6 = cv2.threshold(f5, 15, 255, cv2.THRESH_BINARY)\n",
        "    mask = np.ones(f5.shape[:2], dtype=\"uint8\") * 255\n",
        "    im2, contours, hierarchy = cv2.findContours(f6.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) <= 200:\n",
        "            cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
        "    im = cv2.bitwise_and(f5, f5, mask=mask)\n",
        "    ret, fin = cv2.threshold(im, 15, 255, cv2.THRESH_BINARY_INV)\n",
        "    newfin = cv2.erode(fin, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)), iterations=1)\n",
        "    cv2.imwrite('extract_bv_remove_small_contours.jpg', newfin)\n",
        "    # removing blobs of microaneurysm & unwanted bigger chunks taking in consideration they are not straight lines like blood\n",
        "    # vessels and also in an interval of area\n",
        "    fundus_eroded = cv2.bitwise_not(newfin)\n",
        "    xmask = np.ones(image.shape[:2], dtype=\"uint8\") * 255\n",
        "    x1, xcontours, xhierarchy = cv2.findContours(fundus_eroded.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for cnt in xcontours:\n",
        "        shape = \"unidentified\"\n",
        "        peri = cv2.arcLength(cnt, True)\n",
        "        approx = cv2.approxPolyDP(cnt, 0.04 * peri, False)\n",
        "        if len(approx) > 4 and cv2.contourArea(cnt) <= 3000 and cv2.contourArea(cnt) >= 100:\n",
        "            shape = \"circle\"\n",
        "        else:\n",
        "            shape = \"veins\"\n",
        "        if (shape == \"circle\"):\n",
        "            cv2.drawContours(xmask, [cnt], -1, 0, -1)\n",
        "\n",
        "    finimage = cv2.bitwise_and(fundus_eroded, fundus_eroded, mask=xmask)\n",
        "    blood_vessels = cv2.bitwise_not(finimage)\n",
        "    dilated = cv2.erode(blood_vessels, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)), iterations=1)\n",
        "    cv2.imwrite('extract_bv_remove_big_contours.jpg', dilated)\n",
        "    # dilated1 = cv2.dilate(blood_vessels, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)), iterations=1)\n",
        "    blood_vessels_1 = cv2.bitwise_not(dilated)\n",
        "    return blood_vessels_1\n",
        "def predict(image2predict):\n",
        "    model1 = Sequential()\n",
        "    model1.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "    model1.add(Activation('relu'))\n",
        "    model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model1.add(Conv2D(32, (3, 3)))\n",
        "    model1.add(Activation('relu'))\n",
        "    model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model1.add(Conv2D(64, (3, 3)))\n",
        "    model1.add(Activation('relu'))\n",
        "    model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model1.add(Flatten())\n",
        "    model1.add(Dense(64))\n",
        "    model1.add(Activation('relu'))\n",
        "    model1.add(Dropout(0.5))\n",
        "    model1.add(Dense(1))\n",
        "    model1.add(Activation('sigmoid'))\n",
        "    model1.compile(loss='binary_crossentropy',\n",
        "                optimizer='rmsprop',\n",
        "                metrics=['accuracy'])\n",
        "    model1.load_weights('model.h5')\n",
        "    fundus1 = cv2.imread(image2predict)\n",
        "    fundus = cv2.resize(fundus1, (800, 615))\n",
        "    fundus_mask = cv2.imread(\"MASK.bmp\")\n",
        "    fundus_mask = cv2.resize(fundus_mask, (800, 615))\n",
        "    f1 = cv2.bitwise_and(fundus[:, :, 0], fundus_mask[:, :, 0])\n",
        "    f2 = cv2.bitwise_and(fundus[:, :, 1], fundus_mask[:, :, 1])\n",
        "    f3 = cv2.bitwise_and(fundus[:, :, 2], fundus_mask[:, :, 2])\n",
        "    fundus_dash = cv2.merge((f1, f2, f3))\n",
        "    cv2.imwrite('1-masking.jpg', fundus_dash)\n",
        "\n",
        "    b, g, r = cv2.split(fundus_dash)\n",
        "    hsv_fundus = cv2.cvtColor(fundus_dash, cv2.COLOR_BGR2HSV)\n",
        "    h, s, v = cv2.split(hsv_fundus)\n",
        "    gray_scale = cv2.cvtColor(fundus_dash, cv2.COLOR_BGR2GRAY)\n",
        "    cv2.imwrite('2-gray_scale.jpg', gray_scale)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    contrast_enhanced_fundus = clahe.apply(gray_scale)\n",
        "    cv2.imwrite('3-histogram-gray_scale.jpg', contrast_enhanced_fundus)\n",
        "    contrast_enhanced_green_fundus = clahe.apply(g)\n",
        "    cv2.imwrite('4-contrast_enhanced_green_fundus.jpg', contrast_enhanced_green_fundus)\n",
        "\n",
        "    average_intensity = get_average_intensity(contrast_enhanced_green_fundus) / 255\n",
        "    average_hue = get_average_hue(h) / 255\n",
        "    average_saturation = get_average_saturation(s) / 255\n",
        "\n",
        "    bv_image_dash = extract_bv(g)\n",
        "    cv2.imwrite('5-green-extract_bv.jpg', bv_image_dash)\n",
        "    bv_image = extract_bv(gray_scale)\n",
        "    cv2.imwrite('6-gray_scale-extract_bv.jpg', bv_image)\n",
        "\n",
        "    var_fundus = standard_deviation_image(contrast_enhanced_fundus)\n",
        "\n",
        "    edge_feature_output = edge_pixel_image(gray_scale, bv_image)\n",
        "    cv2.imwrite('7-removeUnionBetweenCanny-over-originaland.jpgBv_image.jpg', edge_feature_output)\n",
        "    newfin = cv2.dilate(edge_feature_output, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)), iterations=1)\n",
        "    cv2.imwrite('8-dilateWithMORPH_ELLIPSE.jpg', newfin)\n",
        "    edge_candidates = cv2.erode(newfin, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)), iterations=1)\n",
        "\n",
        "    edge_candidates = np.uint8(edge_candidates)\n",
        "    cv2.imwrite('9-ErosionWithMORPH_ELLIPSE.jpg', edge_candidates)\n",
        "\n",
        "    cv2.imwrite('10.jpg', edge_candidates)\n",
        "    img = cv2.imread('10.jpg')\n",
        "    img = np.reshape(img,[1,615,800,3])\n",
        "    classes = model1.predict_classes(img)\n",
        "    if (classes[0][0]==1):\n",
        "        print('yes')\n",
        "    else:\n",
        "        print('no')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}